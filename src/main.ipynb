{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1d8f6f0",
   "metadata": {},
   "source": [
    "## Analiza Atencji dla STSA-Net do rozpoznawania ćwiczeń\n",
    "\n",
    "\n",
    "### Wczytanie zbioru danych\n",
    "\n",
    "TODO: dodanie wczytania zbioru danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff6e1b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9ce9c14",
   "metadata": {},
   "source": [
    "### Zdefiniowanie sieci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d865ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "DEBUG = False\n",
    "DROPOUT = 0.1\n",
    "NUM_HEADS = 4\n",
    "FFN_MULT = 4\n",
    "NUM_JOINTS = 41\n",
    "JOINT_DIM = 36\n",
    "NUM_CLASSES = 6\n",
    "T = 7\n",
    "H = 16\n",
    "\n",
    "class SpatialAttentionBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, H, num_heads=8, dropout=DROPOUT):\n",
    "        super().__init__()\n",
    "        self.mha = nn.MultiheadAttention(embed_dim=H, num_heads=num_heads, dropout=dropout, batch_first=True)\n",
    "        self.norm = nn.LayerNorm(H)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, J, H = x.shape\n",
    "        xt = x.reshape(B * T, J, H)\n",
    "        out, _ = self.mha(xt, xt, xt, need_weights=False)\n",
    "        out = self.dropout(out)\n",
    "        out = out + xt\n",
    "        out = self.norm(out)\n",
    "        out = out.reshape(B, T, J, H)\n",
    "        return out\n",
    "\n",
    "\n",
    "class TemporalAttentionBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, H, num_heads=8, dropout=DROPOUT):\n",
    "        super().__init__()\n",
    "        self.mha = nn.MultiheadAttention(embed_dim=H, num_heads=num_heads, dropout=dropout, batch_first=True)\n",
    "        self.norm = nn.LayerNorm(H)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, J, H = x.shape\n",
    "        xt = x.permute(0, 2, 1, 3).reshape(B * J, T, H)\n",
    "        out, _ = self.mha(xt, xt, xt, need_weights=False)\n",
    "        out = self.dropout(out)\n",
    "        out = out + xt\n",
    "        out = self.norm(out)\n",
    "        out = out.reshape(B, J, T, H).permute(0, 2, 1, 3)\n",
    "        return out\n",
    "\n",
    "\n",
    "class STSABlock(nn.Module):\n",
    "\n",
    "    def __init__(self, H, num_heads=NUM_HEADS, dropout=DROPOUT, ffn_mult=FFN_MULT):\n",
    "        super().__init__()\n",
    "        self.s_attn = SpatialAttentionBlock(H, num_heads=num_heads, dropout=dropout)\n",
    "        self.t_attn = TemporalAttentionBlock(H, num_heads=num_heads, dropout=dropout)\n",
    "\n",
    "        self.ffn_norm = nn.LayerNorm(H)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(H, H * ffn_mult),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(H * ffn_mult, H),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        self.final_norm = nn.LayerNorm(H)\n",
    "\n",
    "    def forward(self, x):\n",
    "        s = self.s_attn(x)\n",
    "        x = x + s\n",
    "\n",
    "        t = self.t_attn(x)\n",
    "        x = x + t\n",
    "\n",
    "        B, T, J, H = x.shape\n",
    "        y = x.reshape(B * T * J, H)\n",
    "        y = self.ffn(y)\n",
    "        y = y.reshape(B, T, J, H)\n",
    "        x = x + y\n",
    "\n",
    "        x = self.final_norm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class STSANet(nn.Module):\n",
    "    def __init__(self, T=T, J=NUM_JOINTS, D=JOINT_DIM, H=H, num_classes=NUM_CLASSES,\n",
    "                 num_heads=NUM_HEADS, dropout=DROPOUT, ffn_mult=FFN_MULT, num_blocks=2):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        self.J = J\n",
    "        self.D = D\n",
    "        self.H = H\n",
    "\n",
    "        self.embed = nn.Linear(D, H)\n",
    "\n",
    "        self.pos_time = nn.Parameter(torch.randn(1, T, 1, H) * 0.02)\n",
    "        self.pos_joint = nn.Parameter(torch.randn(1, 1, J, H) * 0.02)\n",
    "\n",
    "        blocks = []\n",
    "        for _ in range(num_blocks):\n",
    "            blocks.append(STSABlock(H, num_heads=num_heads, dropout=dropout, ffn_mult=ffn_mult))\n",
    "        self.blocks = nn.ModuleList(blocks)\n",
    "\n",
    "        self.pool_norm = nn.LayerNorm(H)\n",
    "        self.cls = nn.Linear(H, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, J, D = x.shape\n",
    "\n",
    "        x = self.embed(x)\n",
    "        x = x + self.pos_time + self.pos_joint\n",
    "\n",
    "        for idx, blk in enumerate(self.blocks):\n",
    "            x = blk(x)\n",
    "\n",
    "        x = self.pool_norm(x)\n",
    "        pooled = x.mean(dim=(1, 2))\n",
    "        logits = self.cls(pooled)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd2642a",
   "metadata": {},
   "source": [
    "### Trening\n",
    "\n",
    "TODO: Trzeba dodać coś co zamieni dataset na pytorchowe dataloadery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a807a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "DEVICE = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "NUM_CLASSES = 6\n",
    "NUM_EPOCHS = 20\n",
    "LR = 0.5e-3\n",
    "\n",
    "model = STSANet().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='max', factor=0.5, patience=3\n",
    ")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    train_preds_all = []\n",
    "    train_labels_all = []\n",
    "\n",
    "    for clips, labels in tqdm.tqdm(train_loader, desc=\"Training\"):\n",
    "        clips = clips.to(DEVICE, non_blocking=True)\n",
    "        labels = labels.to(DEVICE, non_blocking=True).long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(clips)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * clips.size(0)\n",
    "\n",
    "        _, preds = outputs.max(1)\n",
    "        \n",
    "        train_preds_all.append(preds.cpu().numpy())\n",
    "        train_labels_all.append(labels.cpu().numpy())\n",
    "\n",
    "    train_preds_all = np.concatenate(train_preds_all)\n",
    "    train_labels_all = np.concatenate(train_labels_all)\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_labels_all)\n",
    "    train_f1 = f1_score(train_labels_all, train_preds_all, average='macro')\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_preds_all = []\n",
    "    val_labels_all = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for clips, labels in tqdm.tqdm(val_loader, desc=f\"Epoch {epoch+1} [Valid]\"):\n",
    "            clips = clips.to(DEVICE, non_blocking=True)\n",
    "            labels = labels.to(DEVICE, non_blocking=True).long()\n",
    "\n",
    "            outputs = model(clips)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * clips.size(0)\n",
    "\n",
    "            _, preds = outputs.max(1)\n",
    "            \n",
    "            val_preds_all.append(preds.cpu().numpy())\n",
    "            val_labels_all.append(labels.cpu().numpy())\n",
    "\n",
    "    val_preds_all = np.concatenate(val_preds_all)\n",
    "    val_labels_all = np.concatenate(val_labels_all)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_labels_all)\n",
    "    val_f1 = f1_score(val_labels_all, val_preds_all, average='macro')\n",
    "\n",
    "    scheduler.step(val_f1)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{NUM_EPOCHS}] \"\n",
    "        f\"Train Loss: {avg_train_loss:.4f} | Train F1: {train_f1:.4f} \"\n",
    "        f\"| Val Loss: {avg_val_loss:.4f} | Val F1: {val_f1:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf6a3f6",
   "metadata": {},
   "source": [
    "### Analiza atencji modelu\n",
    "\n",
    "TODO: Będzie trzeba dodać hooki do layerów modelu i zbierać gdzieś informacje o atencji i je wyplotować."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
